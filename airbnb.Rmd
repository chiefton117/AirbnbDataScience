---
title: "AirBNB Data Analysis"
author: "Tim Harrold, Madison Brown, Yifei Hao"
date: "3/10/2021"
output: html_document
---

Our data was sourced from airbnb's website: http://insideairbnb.com/get-the-data.html    

In this analysis we will be observing qualitative and quantitative characteristics to discover the variation in Airbnbs throughout New York City, and what makes the best Airbnb experience. We ask the question, which characteristics (variables) are correlated with a better reported experience.    

This analysis will include graphs to show the relationships between price and neighborhood, rating and neighborhood, rating and number of reviews, and rating and review stop words. We will be using tables, density plots, scatter plots, box plots, and maps to analyze the correlations between these variables. To give a qualitative analysis of peoples stays, we will be using word cloud to filter keywords from the reviews. A map of the city will provide spacial information on where the most vs least expensive Airbnbs are located in the city. We hypothesize that the Bronx and Brooklyn will have the higher densities of lower priced Airbnbs than Staten Island and Manhattan, and that there will be a positive correlation between price and review score. We hypothesize that the map will show the highest concentration of higher priced Airbnbs in Manhattan. In the cloud word, we hypothesize that better words will obviously correlate with better experiences, and better experiences may mention Manhattan or Brooklyn.     

We don't believe in any sampling bias in this observational study, as this data is from an objective database of ALL airbnb listings. These listings included metadata that we're pulling from, such as price, reviews, and location.    

There was a lot of data cleaning done to produce this data over many iterations. A private github repo / git log of all commits can be produced upon request. Some methods include:    

- Scrubbing language of all punctuation and non-alphanumeric characters
- Taking a random sample of the data and finding a subset within one std deviation of the mean
- Removing extraneous values from graphs for easier viewing


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(devtools)
library(maps)
library(leaflet)
library(ggmap)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggwordcloud)
library(grid)
library(gridExtra)


listings <- read.csv('listings_NYC.csv');
reviews <- read.csv('reviews_NYC.csv');

# In the setup chunk, create a numeric casting of price for analysis in the rest of the code
listings$priceNum <- as.numeric(gsub('[$,]', '', listings$price))

```

## Density by Price

This graph show the density of Airbnbs at different prices within the five boroughs.  We hypothesized that the Bronx and Brooklyn would have the higher densities of lower priced Airbnbs than Staten Island and Manhattan. Our hypothesis is only partially correct. Brooklyn has a similar distribution to Staten Island, and queens has a similar distibution to the Bronx. Our hypothesis was supported in the case of the Bronx and Manhattan. This data show that the Bronx contain a higher distribution of lower priced Airbnbs than the other boroughs. Manhattan has the lowest density of lower priced Airbnbs. This is likely due to the difference in housing prices between Manhattan and the Bronx. 

```{r listings, echo=FALSE}


ggplot(data = listings %>% filter(priceNum < 400), mapping = aes(x=priceNum, fill=neighbourhood_group_cleansed)) +
  geom_density() +
  facet_wrap(~ neighbourhood_group_cleansed) +
  guides(fill = FALSE) +
  labs(title = "Airbnb Density by Price",
       x = 'Price',
       y = 'Density') +
  theme(plot.title = element_text(size= 15, face = 'bold'))

##ggplot(data = listings %>% filter(review_scores_rating > 50), mapping = aes(x=review_scores_rating, fill=neighbourhood_group_cleansed)) +
  ##geom_density() +
  ##facet_wrap(~ neighbourhood_group_cleansed)

```
## Review Scores by Price

This graph shows the review score by price of Airbnbs in each borough. We hypothesized that there would be a positive correlation between price and review score. The data show that higher priced Airbnbs tend to have high review scores. Most of the multithousand dollar Airbnbs do not have review scores below 80. Although more expensive Airbnbs trend towards higher scores, this does not mean that cheaper Airbnbs trend towards lower scores. The Airbnbs with the lower scores tend to be the cheaper ones; However, less expensive Airbnbs also have high scores. From this, we conclude that price has less impact on cheaper Airbnb reviews than expensive ones. 

```{r scatter, warning = FALSE}


ggplot(data = listings, mapping = aes(x=priceNum, y=review_scores_rating, color=neighbourhood_group_cleansed)) +
  geom_point() +
  facet_wrap(~ neighbourhood_group_cleansed) +
  guides(fill = FALSE) +
  labs(title = 'Review Scores by Price',
       x = 'Price',
       y = 'Review Score') +
  theme(plot.title = element_text(size=15, face = 'bold')) 


```


# Stop Words 

For this part of the analysis, we will take 20 listings from the top and bottom of the data, then sample another 20 randomly. We will then filter these through a list of stop words(deemed irrelevant to the data) to find relevant and unique words to describe these experiences.

``` {r stopWords}

# First, we'll define our array of stop words
stopWords <- c("airbnb", "a", "about", "above", "above", "across", "after", "afterwards", "again", "against", "algo", "all", "almost", 
    "alone", "along", "alojen", "already", "also","although","always","am", "ammar","among", "amongst", "amoungst", "amount",  
    "an", "and", "another", "any","anyhow","anyone","anything","anyway", "anywhere", "are", "aren't", "arrive", "arrived", "around", "as",  
    "at", "back", "bc", "be","became", "because", "becky", "become","becomes", "becoming", "been", "before", "beforehand", "behind", 
    "being", "below", "beside", "besides", "between", "beyond", "bill", "both", "bottom","but", "by", "call", 
    "can", "cannot", "cant", "card","chaqueta", "chayda", "co", "con", "could", "couldnt", "de", "definitely", 
    "definetely", "dell", "defin", "describe", "detail", "did", "do", "doesn", "doesn't", "done", "don't", "down", "due", "during", 
    "each", "eg", "eight", "either", "eleven","else", "elsewhere", "empty", "enough", "episode", 
    "etc", "even", "ever", "every", "everyone", "everything", "everywhere", "except", "few", "fifteen", "fify", 
    "fill", "find", "fire", "first", "five", "for", "former", "formerly", "forty", "found", "four", "from", 
    "front", "full", "further", "get", "give", "go", "going", "had", "has", "hasnt", "have", "he", "hello", "hence", "her", 
    "here", "hereafter", "hereby", "herein", "hereupon", "hers", "herself", "him", "himself", "his", "how",
    "however", "hundred", "i", "ie", "if", "i'll", "in", "inc", "indeed", "interest", "into", "is", "it", "its", "itâ€™s", "itself", "i've", "just",
    "keep", "la", "last", "latter", "latterly", "least", "leave", "less", "let's", "like", "ltd", "made", "many", "may", "me", "met", "meanwhile", "message",
    "might", "mill", "mine", "more", "moreover", "most", "mostly", "move", "much", "must", "my", "myself", 
    "name", "namely", "neither", "never", "nevertheless", "next", "nine", "no", "nobody", "none", "noone", "nsure", 
    "nor", "not", "nothing", "now", "nowhere", "nthe", "of", "off", "often", "on", "once", "one", "only", "onto", "or", 
    "other", "others", "otherwise", "our", "ours", "ourselves", "out", "over", "own", "para","part", "per", "perhaps", "place", 
    "please", "put", "rather", "re", "room", "same", "see", "seem", "seemed", "seeming", "seems", "serious", "several", 
    "she", "should", "show", "side", "since", "six", "sixty", "so", "some", "somehow", "someone", 
    "something", "sometime", "sometimes", "somewhere", "still", "such", "take", "takes", "ten", "than", 
    "that", "thats", "the", "their", "them", "themselves", "the", "then", "thence", "there", "thereafter", "thereby", "therefore", 
    "therein", "thereupon", "these", "they", "thick", "thin", "third", "this", "those", "though", "three", 
    "through", "throughout", "thru", "thus", "to", "together", "too", "told", "top", "toward", "towards", "twelve", 
    "twenty", "two", "un", "under", "until", "up", "upon", "us", "very", "via", "was", "way", "we", "well", "were", 
    "what", "whatever", "when", "whence", "whenever", "where", "whereafter", "whereas", "whereby", "wherein",
    "whereupon", "wherever", "whether", "which", "while", "whither", "who", "whoever", "whole", "whom", "whose", 
    "why", "will", "with", "within", "without", "would", "year", "years", "yet", "you", "your", "you're", "yours", "yourself", "yourselves", "ve", "", " ")

# replace reviews listing id for join
reviews$id <- reviews$listing_id

# create a new joined frame with less data, for easier analysis
ordered <- listings %>%
  select(id, priceNum, neighbourhood_group_cleansed, review_scores_rating) %>%
  group_by(id, neighbourhood_group_cleansed) %>%
  filter(review_scores_rating == max(review_scores_rating)) %>%
  arrange(desc(review_scores_rating), desc(priceNum))

joined <- as.data.frame(left_join(ordered, reviews, by="id"))

avg_review <- sample_n(joined, 20)
best_review <- head(joined, n=20)
worst_review <- tail(joined, n=20)

# Takes in a data frame and scrubs the review variable with regex - taking out punctuation, numbers and newlines
# NOTE: THIS DATA FRAME MUST HAVE A CHARACTER ATTRIBUTE 'COMMENTS'
filter_regex <- function(data) {
  
  # filter data with regex
  data$comments <- gsub("[^a-zA-Z ]","",data$comments, perl=TRUE, fixed = FALSE)
  
  # split strings and put frequencies in a table
  words <- data.frame(table(unlist(strsplit(tolower(data$comments), " "))))
  
  # name columns and remove stop words
  colnames(words) <- c("word", "count")
    
  words <- words %>% filter((!(words$word %in% stopWords)))
  
}

# Create our data frames by filtering reviews
best <- filter_regex(best_review)
avg <- filter_regex(avg_review)
worst <- filter_regex(worst_review)



```

## Reviews Word Analysis

The first correlation I noticed is the use of more abstract words against the expreience of each airbnb. When a place is better, words like "great", "easy", "flexible",  and "confidence" are used. The finding here is that a better experience may not be distinct in what makes it amazing, but rather there is a lack of inconvenience. It seems that people also value communication and accessibility in their AirBNB experience. "resposive", "accommodating", and many names are listed in these reviews. Perhaps there was a personal element to the stays that added to the experience. It is also worth noting that this is the only word cloud that easily fit into its box - people have a lot less to say when they are satisfied than when they are upset.

Average reviews were somewhere in the middle, where "clean", "available", and "comfortable" showed up often. These aren't generally descriptive of an exceptional experience, and moreso meet the baseline of a good AirBNB. Accessibility is still mentioned with "access", "communication", and "easy". Less names are mentioned in this data, but they are still present. Some people may have had better experiences when more names were mentioned. "Apartment" showed up more than any other word, as was the case with the top 20 graph. In New York City, apartments likely make up most properties. An average stay would probably be in an apartment(although some were in bungalows, apparently).

In our worst experiences, lots of red flags immediately come up. "Felons", "Smell", and "Homeless" are evidently bad. The learning here is the usage of less abstract words and more nouns. It seems specific things were present, and people have a lot to say about specific aspects of their stay. "Bathroom", "Room", "Water", "Basement" and "Smoke" showed up often - these things must contribute to negative experiences. People do not mention accessibility OR names, meaning the owners may not even be present for the experience. Where the best and average stays mentioned apartments, the worst experiences are "places".

Some interesting anomalies in the bad experiences include "sin", "knees", "cameras", "ghost", and "pathological" - one can easily imagine a bad scenario with these words.



```{r reviews, message=FALSE, warning=FALSE}

# Create some word clouds
w1 <- ggplot(data=best, mapping=aes(label=word,size=count)) +
  geom_text_wordcloud(rm_outside = TRUE, area_corr_power = 1) +
  scale_size_area(max_size = 8) +
  theme_bw() +
  labs(title="NYC AirBnb Unique Word Frequency", subtitle="Top 20 Reviews")

w2 <- ggplot(data=avg, mapping=aes(label=word,size=count)) +
  geom_text_wordcloud(rm_outside = TRUE, area_corr_power = 1) +
  scale_size_area(max_size = 12) +
  theme_bw() +
  labs(title="NYC AirBnb Unique Word Frequency", subtitle="20 Randomly Sampled Reviews")

w3 <- ggplot(data=worst, mapping=aes(label=word,size=count)) +
  geom_text_wordcloud(rm_outside = TRUE, area_corr_power = 1) +
  scale_size_area(max_size = 12) +
  theme_bw() +
  labs(title="NYC AirBnb Unique Word Frequency", subtitle="Worst 20 Reviews")

# a grid.arrange approach cut too much from the boxes, making analysis harder
w1
w2
w3

```


## Box Plot of Price

(Working on this description- Madison)

```{r boxplot}
boxplot <- as.data.frame(sample_n(listings, 1500))

ggplot(data = boxplot %>% filter(priceNum < 2000), 
       mapping = aes(x = neighbourhood_group_cleansed, y = priceNum, fill = neighbourhood_group_cleansed)) +
  geom_boxplot() +
  theme(plot.title = element_text(size= 15, face = 'bold')) +
  labs(title = 'Price by Neighborhood',
       x = 'Neighborhood',
       y = 'Price') +
  guides(fill = FALSE) +
  theme_bw()
  

```

## Scatter plot of Ratings by Price


(Working on this Description- Madison)

```{r scatterprice, warning = FALSE}

set.seed(129)
scatter <- as.data.frame(sample_n(listings, 1000))

ggplot(data = listings, mapping = aes(x=priceNum, y=review_scores_rating, color=neighbourhood_group_cleansed)) +
  geom_point() +
  facet_wrap(~ neighbourhood_group_cleansed) +
  theme_bw() +
  labs(title = 'Ratings by Price',
       x = 'Review Score',
       y = 'Number of Reviews') +
   theme(plot.title = element_text(size= 15, face = 'bold'))



 
```


## Mapped Listings by Price

Here, we tried to utilize ggmaps and ggplot before resorting to leaflet for our map. I tried mapping the review scores, which didn't quite display right(most scores are actually pretty high!) even when mapping 68% of the data within one standard deviation of the mean.

The other challenge was taking a small enough subset of the data to map without crashing a computer(three computer crashes were involved in the making of this report). Leaflet offers multiple coloring methods, such as numerical, bin-based, and quantile-based. Quantiles ended up working especially well for this map.

This map has some interesting findings in the density of properties, and their price. The listings get much more dense the further into Manhattan you go, second to Queens and Brooklyn. Interestingly, price also increases as you get into these areas. As per our earlier findings, Manhattan and Brooklyn are the most expensive boroughs to stay in.

Within Manhattan, values get more dense and more expensive towards the south end. This is the financial district of NYC, where most skyscrapers and businesses are. Perhaps people with financial interests, or wealthier individuals like Wall Street bankers stay in pricier AirBNB's. SoHo and Greenwich Village are also in this part of Manhattan, which must be more expensive.

When people visit NYC, they want to be closer to the center of the city. They likely pay more for staying in or near Manhattan - where most tourist attractions are.

```{r maps, force = TRUE, message=FALSE, warning=FALSE}

set.seed(200)
subset <- sample_n(listings, 3000)

stdev <- sd(subset$priceNum)
mean <- mean(subset$priceNum)


# This is within one standard deviation of the mean
sData <- subset %>% filter(priceNum > (mean - stdev) & priceNum < (mean + stdev))
# This is within two standard deviations of the mean
sd2Data <- subset %>% filter(priceNum > mean - (2*stdev) & priceNum < mean + (2*stdev))

clrs <- colorQuantile(palette = "RdYlBu", domain = sData$priceNum, reverse = TRUE, na.color = NA)

# plot price on map, not sure what the actual markers signify?
leaflet(sData) %>%
  addTiles() %>%
  addCircleMarkers(data = sData,
           lng = ~longitude,
           lat = ~latitude,
           color = ~clrs(priceNum),
           stroke = FALSE, fillOpacity = 0.4, radius = 4) %>%
  addLegend("bottomright", pal = clrs, values = ~priceNum,
    title = "Price(Quantile)",
    labFormat = labelFormat(prefix = ""),
    opacity = 1) %>%
  addMarkers( clusterOptions = markerClusterOptions() ) %>%
  setView(-74.00, 40.71, zoom = 12) %>%
  addProviderTiles("CartoDB.Positron")

```

## Conclusions



## Limitations

This data was very thorough, expansive and full of opportunities for analysis. While we found some great conclusions, the size of the data presented a limitation for us. Several parts of the data were not computationally feasible for all 37k+ listings, so we took random samples that may not have been represenatative. This study does not utilize many variables to find what correlates with positive reviews, such as bed count or accomodations. In the future, one could use more variables to see what neighborhoods or conditions make for a better experience. One could also analyze each neighborhood or borough independently. Manhattan obviously has another level of experience than the Bronx. Thus, a good AirBNB in the Bronx might be subpar in Manhattan. Analyzing what makes the experience better by neighborhood could be more individualized, as it could be based on different goals and variables.