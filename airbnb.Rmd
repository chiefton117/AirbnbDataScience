---
title: "AirBNB Data Analysis"
author: "Tim Harrold, Madison brown, Yifei Hao"
date: "3/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggplot2)
library(dplyr)
library(ggwordcloud)

# The map theme taken from the book
theme_map <- function(base_size=9, base_family="") {
    require(grid)
    theme_bw(base_size=base_size, base_family=base_family) %+replace%
        theme(axis.line=element_blank(),
              axis.text=element_blank(),
              axis.ticks=element_blank(),
              axis.title=element_blank(),
              panel.background=element_blank(),
              panel.border=element_blank(),
              panel.grid=element_blank(),
              panel.spacing=unit(0, "lines"),
              plot.background=element_blank(),
              legend.justification = c(0,0),
              legend.position = c(0,0)
              )
}

```

## Setting up the project

First, get our data from:

http://insideairbnb.com/get-the-data.html


To create these two files, right click the files listings.csv.gz and reviews.csv.gz separately, and click "extract here" or "extract to -> listings.csv", just like we extract the .zip files in class

Before committing and pushing, go to github desktop after you have the data files. Where it lists each file with a checkbox, right click the data files "listings.csv,reviews.csv,listings.csv.gz" and click:     
"ignore all .csv files(add to .gitignore)", then     
"ignore all .gz files(add to .gitignore)". 

If the data files are not removed from the list, right click them again and click "Ignore File(add to .gitignore). This will make it so you don't submit large data to the cloud. Github will not accept these large files(even the compressed ones) because of the size of our data.

```{r setup}


listings <- read.csv('listings_NYC.csv');
reviews <- read.csv('reviews.csv');


```

## Make some graphs!

Some relevant variables-

number_of_reviews_ltm
number_of_reviews

review_scores_rating


```{r listings, echo=FALSE}


tibble(listings)
listings$priceNum <- as.numeric(gsub('[$,]', '', listings$price))

ggplot(data = listings, mapping = aes(x=neighbourhood_group_cleansed, color=neighbourhood_group_cleansed)) +
  geom_boxplot()

ggplot(data = listings, mapping = aes(x=neighbourhood_group_cleansed, fill=neighbourhood_group_cleansed)) +
  geom_density()


ggplot(data = listings %>% filter(priceNum < 400), mapping = aes(x=priceNum, fill=neighbourhood_group_cleansed)) +
  geom_density() +
  facet_wrap(~ neighbourhood_group_cleansed)

ggplot(data = listings %>% filter(priceNum < 400), mapping = aes(x=priceNum, fill=neighbourhood_group_cleansed)) +
  geom_bar()

ggplot(data = listings, mapping = aes(x=priceNum, y=review_scores_rating, color=neighbourhood_group_cleansed)) +
  geom_point() +
  facet_wrap(~ neighbourhood_group_cleansed)


#ggplot(data = listings, mapping = aes(x=number_of_reviews, y=priceNum, color=neighbourhood_group_cleansed)) +
#  geom_point()




```

``` {r stopWords}

stopWords <- c("a", "about", "above", "above", "across", "after", "afterwards", "again", "against", "all", "almost", 
    "alone", "along", "already", "also","although","always","am","among", "amongst", "amoungst", "amount",  
    "an", "and", "another", "any","anyhow","anyone","anything","anyway", "anywhere", "are", "aren't", "around", "as",  
    "at", "back", "bc", "be","became", "because","become","becomes", "becoming", "been", "before", "beforehand", "behind", 
    "being", "below", "beside", "besides", "between", "beyond", "bill", "both", "bottom","but", "by", "call", 
    "can", "cannot", "cant", "co", "con", "could", "couldnt", "de", "definitely", "definetely", "defin", "describe", "detail", "did", "do", "done", "don't", 
    "down", "due", "during", "each", "eg", "eight", "either", "eleven","else", "elsewhere", "empty", "enough", "episode", 
    "etc", "even", "ever", "every", "everyone", "everything", "everywhere", "except", "few", "fifteen", "fify", 
    "fill", "find", "fire", "first", "five", "for", "former", "formerly", "forty", "found", "four", "from", 
    "front", "full", "further", "get", "give", "go", "going", "had", "has", "hasnt", "have", "he", "hello", "hence", "her", 
    "here", "hereafter", "hereby", "herein", "hereupon", "hers", "herself", "him", "himself", "his", "how",
    "however", "hundred", "i", "ie", "if", "i'll", "in", "inc", "indeed", "interest", "into", "is", "it", "its", "itâ€™s", "itself", "i've", "just",
    "keep", "last", "latter", "latterly", "least", "leave", "less", "let's", "like", "ltd", "made", "many", "may", "me", "met", "meanwhile", 
    "might", "mill", "mine", "more", "moreover", "most", "mostly", "move", "much", "must", "my", "myself", 
    "name", "namely", "neither", "never", "nevertheless", "next", "nine", "no", "nobody", "none", "noone", 
    "nor", "not", "nothing", "now", "nowhere", "of", "off", "often", "on", "once", "one", "only", "onto", "or", 
    "other", "others", "otherwise", "our", "ours", "ourselves", "out", "over", "own","part", "per", "perhaps", 
    "please", "put", "rather", "re", "same", "see", "seem", "seemed", "seeming", "seems", "serious", "several", 
    "she", "should", "show", "side", "since", "six", "sixty", "so", "some", "somehow", "someone", 
    "something", "sometime", "sometimes", "somewhere", "still", "such", "take", "takes", "ten", "than", 
    "that", "thats", "the", "their", "them", "themselves", "the", "then", "thence", "there", "thereafter", "thereby", "therefore", 
    "therein", "thereupon", "these", "they", "thick", "thin", "third", "this", "those", "though", "three", 
    "through", "throughout", "thru", "thus", "to", "together", "too", "told", "top", "toward", "towards", "twelve", 
    "twenty", "two", "un", "under", "until", "up", "upon", "us", "very", "via", "was", "way", "we", "well", "were", 
    "what", "whatever", "when", "whence", "whenever", "where", "whereafter", "whereas", "whereby", "wherein",
    "whereupon", "wherever", "whether", "which", "while", "whither", "who", "whoever", "whole", "whom", "whose", 
    "why", "will", "with", "within", "without", "would", "year", "years", "yet", "you", "your", "you're", "yours", "yourself", "yourselves", "ve", "")

# replace reviews listing id for join
reviews$id <- reviews$listing_id

top_10 <- listings %>%
  select(id, priceNum, neighbourhood_group_cleansed, review_scores_rating) %>%
  group_by(id, neighbourhood_group_cleansed) %>%
  filter(review_scores_rating == max(review_scores_rating)) %>%
  arrange(desc(review_scores_rating), desc(priceNum))

joined <- left_join(top_10, reviews, by="id")

avg_review <- sample_n(joined, 10, replace=TRUE)
best_review <- head(joined, n=10)
worst_review <- tail(joined, n=10)


```


```{r reviews}

sample <- tolower(head(reviews$comments, 10))
sample <- gsub("[\\\r\n\\.\\,[:digit:]+]","",sample, perl=TRUE, fixed = FALSE)
sample <- gsub('[[:punct:] ]+',' ',sample)

words <- data.frame(word = setdiff(str_split(sample, " ", simplify=TRUE), stopWords)) %>% 
  filter(nchar(word) > 2)

#colnames(words) <- c("word")
freqs <- words %>% count(word) %>% arrange(desc(n))
words
freqs

#remove all 3 letter or less words


words.freq<-table(unlist(words))
cbind(names(words.freq),as.integer(words.freq))


#ggplot(data=words, mapping=aes(label=word,size=frequency)) +
#  geom_text_wordcloud(rm_outside = TRUE) +
#  theme_bw()


# frequency table for words
#a.freq<-table(unlist(a))
#cbind(names(a.freq),as.integer(a.freq))


```


```{r maps,}

#DO NOT RUN THIS CODE
#IT WILL MAKE YOUR COMPUTER CRASH
#possibly because data size is too big?
#lat0 and lat1 are probably set incorrectly too, as our area is NYC, not America
#ggplot(data = listings, mapping=aes(x=longitude,y=latitude, fill=priceNum)) +
#  geom_polygon() +
#  scale_fill_continuous(low='white', high='purple') +
#  coord_map(projection="albers", lat0=39,lat1=45) +
#  theme_map()


```